{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.1.2+cu118\n",
      "cuda version: 11.8\n",
      "cuda available\n",
      "muti device count: 4\n",
      "/home/gao/haiwu/block-aigc\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import torch\n",
    "print('torch version:',torch.__version__)\n",
    "print('cuda version:',torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "else:\n",
    "    print('cuda unavailable')\n",
    "print('muti device count:', torch.cuda.device_count())\n",
    "\n",
    "import os\n",
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "# 定义转换来加载图像数据\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将PIL图像或NumPy数组转换为FloatTensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10数据集\n",
    "trainset = datasets.CIFAR10(root='./data/cifar', train=True, download=True, transform=transform)\n",
    "print(trainset.data.shape)\n",
    "# 创建temp文件夹，如果它不存在的话\n",
    "os.makedirs('./temp/src', exist_ok=True)\n",
    "\n",
    "# 为每个标签创建子文件夹并保存图片\n",
    "labels = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "for label_index in range(10):\n",
    "    label_folder = os.path.join('./temp/src', labels[label_index])\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    \n",
    "    # 初始化计数器\n",
    "    count = 0\n",
    "    for i in range(len(trainset)):\n",
    "        # 获取数据和标签\n",
    "        data, label = trainset[i]\n",
    "        if label == label_index and count < 10:\n",
    "            # 保存图像\n",
    "            img_name = os.path.join(label_folder, f\"{count}.png\")\n",
    "            count += 1\n",
    "            # 将数据保存为图像\n",
    "            # print(data.shape) (3,32,32)\n",
    "            xset = data.unsqueeze(0)\n",
    "            grid = make_grid(xset, normalize=True, value_range=(-1, 1), nrow=1)\n",
    "            save_image(grid, img_name)\n",
    "\n",
    "print(\"图片保存完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from pp import fid_score\n",
    "# 准备真实数据分布和生成模型的图像数据\n",
    "real_images_folder = './temp/src/bird/'\n",
    "generated_images_folder = './temp/src/bird/'\n",
    "# 加载预训练的Inception-v3模型\n",
    "inception_model = torchvision.models.inception_v3(pretrained=True)\n",
    "# 定义图像变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将PIL图像或NumPy数组转换为FloatTensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 标准化\n",
    "])\n",
    "# 计算FID距离值\n",
    "fid_value = fid_score.calculate_fid_given_paths([real_images_folder, generated_images_folder],inception_model,device='cuda:0',dims=(1,3,32,32))\n",
    "print('FID value:', fid_value)\n",
    "\n",
    "## python -m pytorch_fid ./temp/src/bird ./temp/src/car --device cuda:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from collections import defaultdict\n",
    "\n",
    "# 加载mnist数据集\n",
    "trainset = datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(trainset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 5 has 5421 images\n",
      "Label 0 has 5923 images\n",
      "Label 4 has 5842 images\n",
      "Label 1 has 6742 images\n",
      "Label 9 has 5949 images\n",
      "Label 2 has 5958 images\n",
      "Label 3 has 6131 images\n",
      "Label 6 has 5918 images\n",
      "Label 7 has 6265 images\n",
      "Label 8 has 5851 images\n"
     ]
    }
   ],
   "source": [
    "# 按照label划分数据集\n",
    "def create_label_dict(dataset):\n",
    "    label_dict = defaultdict(list)\n",
    "    for image,label in dataset:\n",
    "        label_dict[label].append(image)\n",
    "    return label_dict\n",
    "label_dict = create_label_dict(trainset)\n",
    "for label in label_dict:\n",
    "    print(f\"Label {label} has {len(label_dict[label])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 10 images from label 0, shape: torch.Size([10, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def sample_data(label_dict, label, num_samples):\n",
    "    import random\n",
    "    # 从指定标签中随机抽取指定数量的样本\n",
    "    data = random.sample(label_dict[label], num_samples)\n",
    "    # 返回 num_sample, 28, 28的张量\n",
    "    data = torch.stack(data)\n",
    "    data = data.squeeze(1)\n",
    "    return data\n",
    "label = 0\n",
    "num_samples = 10\n",
    "sampled_data = sample_data(label_dict, label, num_samples)\n",
    "print(f\"Sampled {len(sampled_data)} images from label {label}, shape: {sampled_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 28, 28]) torch.Size([20])\n",
      "torch.Size([20, 28, 28]) torch.Size([20])\n",
      "torch.Size([40, 28, 28]) torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "label1 = 1\n",
    "label2 = 2\n",
    "data1 = sample_data(label_dict, label1, num_samples)\n",
    "labels1 = torch.full((num_samples,), label1)\n",
    "data2 = sample_data(label_dict, label2, num_samples)\n",
    "label2 = torch.full((num_samples,), label2)\n",
    "\n",
    "build_images_a = torch.cat([data1,data2], dim=0) # 10个1 10个2\n",
    "build_labels_a = torch.cat([labels1, label2], dim=0)\n",
    "print(build_images_a.shape, build_labels_a.shape)\n",
    "\n",
    "label3 = 3\n",
    "data3 = sample_data(label_dict, label3, num_samples)\n",
    "labels3 = torch.full((num_samples,), label3)\n",
    "build_images_b = torch.cat([data1,data3], dim=0) # 10个3 10个1\n",
    "build_labels_b = torch.cat([labels1,labels3], dim=0)\n",
    "print(build_images_b.shape, build_labels_b.shape)\n",
    "\n",
    "build_images_all = torch.cat([build_images_a, build_images_b], dim=0) # 20个1 10个2 10个3\n",
    "build_labels_all = torch.cat([build_labels_a, build_labels_b], dim=0)\n",
    "print(build_images_all.shape, build_labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMD between two datasets: 1.0\n",
      "EMD between two datasets: 0.5\n",
      "EMD between two datasets: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def calculate_emd(labels1, labels2, labels_cnt=10):\n",
    "    # 计算labels1的频率向量\n",
    "    cnt1 = torch.zeros(labels_cnt)\n",
    "    for label in labels1:\n",
    "        cnt1[label] += 1\n",
    "    cnt1 = cnt1 / len(labels1)\n",
    "    # 计算labels2的频率向量\n",
    "    cnt2 = torch.zeros(labels_cnt)\n",
    "    for label in labels2:\n",
    "        cnt2[label] += 1\n",
    "    cnt2 = cnt2 / len(labels2)\n",
    "    # 计算EMD\n",
    "    emd = (cnt1-cnt2).abs().sum()\n",
    "    return emd\n",
    "emd = calculate_emd(build_labels_b, build_labels_a)\n",
    "print(f\"EMD between two datasets: {emd}\")\n",
    "emd = calculate_emd(build_labels_a, build_labels_all)\n",
    "print(f\"EMD between two datasets: {emd}\")\n",
    "emd = calculate_emd(build_labels_b, build_labels_all)\n",
    "print(f\"EMD between two datasets: {emd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset with given avg EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "Label 5 has 5421 images\n",
      "Label 0 has 5923 images\n",
      "Label 4 has 5842 images\n",
      "Label 1 has 6742 images\n",
      "Label 9 has 5949 images\n",
      "Label 2 has 5958 images\n",
      "Label 3 has 6131 images\n",
      "Label 6 has 5918 images\n",
      "Label 7 has 6265 images\n",
      "Label 8 has 5851 images\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from collections import defaultdict\n",
    "\n",
    "# 加载mnist数据集\n",
    "trainset = datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "print(trainset.data.shape)\n",
    "def create_label_dict(dataset):\n",
    "    label_dict = defaultdict(list)\n",
    "    for image,label in dataset:\n",
    "        label_dict[label].append(image)\n",
    "    return label_dict\n",
    "label_dict = create_label_dict(trainset)\n",
    "for label in label_dict:\n",
    "    print(f\"Label {label} has {len(label_dict[label])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 28, 28]) torch.Size([500])\n",
      "torch.Size([500, 28, 28]) torch.Size([500])\n",
      "torch.Size([1000, 28, 28]) torch.Size([1000])\n",
      "cnt1 = tensor([0.1200, 0.1200, 0.1200, 0.1200, 0.1200, 0.0800, 0.0800, 0.0800, 0.0800,\n",
      "        0.0800]) cnt2 = tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "cnt1 = tensor([0.0800, 0.0800, 0.0800, 0.0800, 0.0800, 0.1200, 0.1200, 0.1200, 0.1200,\n",
      "        0.1200]) cnt2 = tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000])\n",
      "EMD between two a and all: tensor(0.2000)\n",
      "EMD between two b and all: tensor(0.2000)\n",
      "avg EMD: tensor(0.2000)\n"
     ]
    }
   ],
   "source": [
    "def sample_data(label_dict, label, num_samples):\n",
    "    import random\n",
    "    # 从指定标签中随机抽取指定数量的样本\n",
    "    data = random.sample(label_dict[label], num_samples)\n",
    "    # 返回 num_sample, 28, 28的张量\n",
    "    data = torch.stack(data)\n",
    "    data = data.squeeze(1)\n",
    "    return data\n",
    "def calculate_emd(labels1, labels2, labels_cnt=10):\n",
    "    # 计算labels1的频率向量\n",
    "    cnt1 = torch.zeros(labels_cnt)\n",
    "    for label in labels1:\n",
    "        cnt1[label] += 1\n",
    "    cnt1 = cnt1 / len(labels1)\n",
    "    # 计算labels2的频率向量\n",
    "    cnt2 = torch.zeros(labels_cnt)\n",
    "    for label in labels2:\n",
    "        cnt2[label] += 1\n",
    "    cnt2 = cnt2 / len(labels2)\n",
    "    print(f\"cnt1 = {cnt1}\", f\"cnt2 = {cnt2}\")\n",
    "    # 计算EMD\n",
    "    emd = (cnt1-cnt2).abs().sum()\n",
    "    return emd\n",
    "label_cnt = 10\n",
    "total_samples = 1000\n",
    "num_samples = total_samples // label_cnt\n",
    "delta = 0.1 # avg EMD = 2*delta\n",
    "more = delta * num_samples\n",
    "images_a = []\n",
    "labels_a = []\n",
    "images_b = []\n",
    "labels_b = []\n",
    "images_all = []\n",
    "labels_all = []\n",
    "for label in range(label_cnt): \n",
    "    sampled_data = sample_data(label_dict, label, num_samples)\n",
    "    # [0,5] more \n",
    "    if label < label_cnt // 2:\n",
    "        images_a.append(sampled_data[:num_samples//2+int(more)])\n",
    "        images_b.append(sampled_data[num_samples//2-int(more):])\n",
    "        labels_a.append(torch.full((num_samples//2+int(more),), label))\n",
    "        labels_b.append(torch.full((num_samples//2-int(more),), label))\n",
    "    else :\n",
    "        images_a.append(sampled_data[:num_samples//2-int(more)])\n",
    "        images_b.append(sampled_data[num_samples//2+int(more):])\n",
    "        labels_a.append(torch.full((num_samples//2-int(more),), label))\n",
    "        labels_b.append(torch.full((num_samples//2+int(more),), label))\n",
    "    images_all.append(sampled_data)\n",
    "    labels_all.append(torch.full((num_samples,), label))\n",
    "images_a = torch.cat(images_a, dim=0)\n",
    "labels_a = torch.cat(labels_a, dim=0)\n",
    "images_b = torch.cat(images_b, dim=0)\n",
    "labels_b = torch.cat(labels_b, dim=0)\n",
    "images_all = torch.cat(images_all, dim=0)\n",
    "labels_all = torch.cat(labels_all, dim=0)\n",
    "print(images_a.shape, labels_a.shape)\n",
    "print(images_b.shape, labels_b.shape)\n",
    "print(images_all.shape, labels_all.shape)\n",
    "emd_a = calculate_emd(labels_a, labels_all)\n",
    "emd_b = calculate_emd(labels_b, labels_all)\n",
    "print(\"EMD between two a and all:\", emd_a)\n",
    "print(\"EMD between two b and all:\", emd_b)\n",
    "print(\"avg EMD:\", (emd_a+emd_b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianshou3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
