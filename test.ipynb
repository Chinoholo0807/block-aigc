{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test cuda available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.1.2+cu118\n",
      "cuda version: 11.8\n",
      "cuda available\n",
      "muti device count: 4\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import torch\n",
    "print('torch version:',torch.__version__)\n",
    "print('cuda version:',torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "else:\n",
    "    print('cuda unavailable')\n",
    "print('muti device count:', torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [3, 6]])\n",
      "tensor([[1, 2, 2],\n",
      "        [4, 3, 3],\n",
      "        [6, 6, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "index = torch.tensor([[0, 1], [1, 2]])\n",
    "# (0->1,0)(0->1,1) , (1->1,0)(1->2,1) \n",
    "output = torch.gather(input, dim=0, index=index)\n",
    "print(output)\n",
    "\n",
    "index = torch.tensor([[0, 1, 1], [1, 0, 0], [1, 1, 0]])\n",
    "# (0,0)(0,1)(0,1) , (1,0->1)(1,1->0)(1,1->0) , (2,0->1)(2,1->1)（2，2->0)\n",
    "output = torch.gather(input, dim=1, index=index)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "torch.Size([3])\n",
      "tensor([1., 3., 5.])\n"
     ]
    }
   ],
   "source": [
    "def extract(v, t, x_shape):\n",
    "    \"\"\"\n",
    "    Extract some coefficients at specified timesteps, then reshape to\n",
    "    [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
    "    \"\"\"\n",
    "    device = t.device\n",
    "    out = torch.gather(v, index=t, dim=0).float().to(device)\n",
    "    print ([t.shape[0]] + [1] * (len(x_shape) - 1))\n",
    "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))\n",
    "v = torch.tensor([1, 2, 3, 4, 5])\n",
    "t = torch.tensor([0, 2, 4])\n",
    "out = extract(v, t, x_shape=(len(t),))\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([1.0000, 0.1000, 0.2000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "alphas_bar = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "T = 3\n",
    "\n",
    "alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]\n",
    "\n",
    "print(alphas_bar_prev.shape)  \n",
    "print(alphas_bar_prev)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ts.shape: torch.Size([4])\n",
      "beta_t.shape torch.Size([11])\n",
      "x.shape: torch.Size([4, 3, 32, 32])\n",
      "eps.shape: torch.Size([4, 3, 32, 32])\n",
      "sqrtab_extract.shape torch.Size([4, 1, 1, 1])\n",
      "x_t.shape torch.Size([4, 3, 32, 32])\n",
      "_ti.shape: torch.Size([4, 1]) \n",
      "_ti: tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]])\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "\n",
    "n_T = 10\n",
    "batch_size = 4\n",
    "_ts = torch.randint(1, n_T + 1, (batch_size,))\n",
    "print('_ts.shape:',_ts.shape) \n",
    "\n",
    "beta2 = 0.02\n",
    "beta1 = 1e-4\n",
    "beta_t = (beta2 - beta1) * torch.arange(0, n_T + 1, dtype=torch.float32) / n_T + beta1\n",
    "sqrt_beta_t = torch.sqrt(beta_t)\n",
    "alpha_t = 1 - beta_t\n",
    "log_alpha_t = torch.log(alpha_t)\n",
    "alphabar_t = torch.cumsum(log_alpha_t, dim=0).exp()\n",
    "sqrtab = torch.sqrt(alphabar_t)\n",
    "oneover_sqrta = 1 / torch.sqrt(alpha_t)\n",
    "sqrtmab = torch.sqrt(1 - alphabar_t)\n",
    "mab_over_sqrtmab_inv = (1 - alpha_t) / sqrtmab\n",
    "print('beta_t.shape',beta_t.shape)\n",
    "\n",
    "x = torch.randn((batch_size,3,32,32))\n",
    "eps = torch.randn_like(x)\n",
    "print('x.shape:',x.shape)\n",
    "print('eps.shape:',eps.shape)\n",
    "print('sqrtab_extract.shape',sqrtab[_ts, None, None, None].shape)\n",
    "x_t = (\n",
    "    sqrtab[_ts, None, None, None] * x\n",
    "    + sqrtmab[_ts, None, None, None] * eps\n",
    ") \n",
    "print('x_t.shape',x_t.shape)\n",
    "\n",
    "simple_i = 5\n",
    "_ti = torch.tensor(simple_i/n_T).repeat(batch_size,1) # repeat(*sizes)函数可以将一个张量在指定的维度上重复多次\n",
    "print('_ti.shape:',_ti.shape,'\\n_ti:',_ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-08-20:17:55\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "folder_name = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "print(folder_name)\n",
    "folder_path = os.path.join(\"extra\",folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
